{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b9198d1c-048c-4a21-91b5-2a3cb09ab9c2",
      "metadata": {
        "id": "b9198d1c-048c-4a21-91b5-2a3cb09ab9c2"
      },
      "source": [
        "Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "84feada5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pydicom in /opt/homebrew/lib/python3.9/site-packages (2.4.4)\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting scikit-learn\n",
            "  Downloading scikit_learn-1.6.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (31 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn) (1.23.1)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn)\n",
            "  Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.6.0-cp39-cp39-macosx_12_0_arm64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed joblib-1.4.2 scikit-learn-1.6.0 scipy-1.13.1 threadpoolctl-3.5.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: matplotlib in /opt/homebrew/lib/python3.9/site-packages (3.8.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (1.23.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/homebrew/lib/python3.9/site-packages (from matplotlib) (6.1.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /opt/homebrew/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy in /opt/homebrew/lib/python3.9/site-packages (1.23.1)\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pandas in /opt/homebrew/lib/python3.9/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /opt/homebrew/lib/python3.9/site-packages (from pandas) (1.23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.9/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pydicom\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "82cd3f73-d061-4892-8790-e9344ebf74cb",
      "metadata": {
        "id": "82cd3f73-d061-4892-8790-e9344ebf74cb"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from sklearn import svm, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import plot_tree\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "504d4944-fe3f-4411-a47a-d6edfc8d46f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "504d4944-fe3f-4411-a47a-d6edfc8d46f0",
        "outputId": "2a37b0d6-35fe-4909-c5c2-0ed54b892964"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Human__TCGA_BRCA__UNC__RNAseq__HiSeq_RNA__01_28_2016__BI__Gene__Firehose_RSEM_log2.cct'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#import metadata + gene expression data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m rna_express \u001b[38;5;241m=\u001b[39m convert_patient_name(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHuman__TCGA_BRCA__UNC__RNAseq__HiSeq_RNA__01_28_2016__BI__Gene__Firehose_RSEM_log2.cct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m mutant \u001b[38;5;241m=\u001b[39m convert_patient_name(pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman__TCGA_BRCA__WUSM__Mutation__GAIIx__01_28_2016__BI__Gene__Firehose_MutSig2CV.cbt\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     10\u001b[0m methyl \u001b[38;5;241m=\u001b[39m convert_patient_name(pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman__TCGA_BRCA__JHU_USC__Methylation__Meth450__01_28_2016__BI__Gene__Firehose_Methylation_Prepocessor.cct\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Human__TCGA_BRCA__UNC__RNAseq__HiSeq_RNA__01_28_2016__BI__Gene__Firehose_RSEM_log2.cct'"
          ]
        }
      ],
      "source": [
        "# metadata patient name has period instead of -\n",
        "def convert_patient_name(df):\n",
        "    new = [x.replace(\".\", \"-\") for x in df.columns]\n",
        "    df.columns = new\n",
        "    return df\n",
        "\n",
        "#import metadata + gene expression data\n",
        "rna_express = convert_patient_name(pd.read_csv(\"Human__TCGA_BRCA__UNC__RNAseq__HiSeq_RNA__01_28_2016__BI__Gene__Firehose_RSEM_log2.cct\", sep = \"\\t\"))\n",
        "mutant = convert_patient_name(pd.read_csv(\"Human__TCGA_BRCA__WUSM__Mutation__GAIIx__01_28_2016__BI__Gene__Firehose_MutSig2CV.cbt\", sep = \"\\t\"))\n",
        "methyl = convert_patient_name(pd.read_csv(\"Human__TCGA_BRCA__JHU_USC__Methylation__Meth450__01_28_2016__BI__Gene__Firehose_Methylation_Prepocessor.cct\", sep = \"\\t\"))\n",
        "miRNA = convert_patient_name(pd.read_csv(\"Human__TCGA_BRCA__BDGSC__miRNASeq__HS_miR__01_28_2016__BI__Gene__Firehose_RPKM_log2.cct\", sep=\"\\t\"))\n",
        "clinical = convert_patient_name(pd.read_excel('brca-clinicalforwiki.xls'))\n",
        "\n",
        "express_feature = rna_express['attrib_name'].to_numpy()\n",
        "mutant_feature = mutant['attrib_name'].to_numpy()\n",
        "methyl_feature = methyl['attrib_name'].to_numpy()\n",
        "miRNA_feature = miRNA['attrib_name'].to_numpy()\n",
        "features = np.concatenate([express_feature, mutant_feature, methyl_feature, miRNA_feature])\n",
        "\n",
        "check_express = rna_express.columns.to_list()[1:]\n",
        "check_mut = mutant.columns.to_list()[1:]\n",
        "check_methyl = methyl.columns.to_list()[1:]\n",
        "check_miRNA = miRNA.columns.to_list()[1:]\n",
        "\n",
        "# function for getting the intersection of all patients w/ gene expression and imaging data\n",
        "def intersection(list_of_list):\n",
        "    union = list_of_list[0]\n",
        "    for l in list_of_list:\n",
        "        union = list(set(union) & set(l))\n",
        "    return union\n",
        "\n",
        "#actually found out that metadata lied and not all gene expression patients indicated have dicom images, load manually\n",
        "patient = ['TCGA-BH-A28Q', 'TCGA-AR-A24X', 'TCGA-E2-A1IK', 'TCGA-E2-A1IE', 'TCGA-AR-A1AQ', 'TCGA-AR-A1AX', 'TCGA-BH-A0E2', 'TCGA-E2-A1LG', 'TCGA-E2-A1L9', 'TCGA-E2-A1L7', 'TCGA-E2-A1IJ', 'TCGA-BH-A0H3', 'TCGA-BH-A0B5', 'TCGA-E2-A1B1', 'TCGA-BH-A0DG', 'TCGA-E2-A1B6', 'TCGA-BH-A0DI', 'TCGA-E2-A15K', 'TCGA-BH-A201', 'TCGA-E2-A15J', 'TCGA-E2-A1IG', 'TCGA-AR-A1AN', 'TCGA-E2-A1II', 'TCGA-E2-A1IN', 'TCGA-AR-A24S', 'TCGA-BH-A0AZ', 'TCGA-BH-A0DV', 'TCGA-E2-A1B5', 'TCGA-BH-A0B6', 'TCGA-BH-A0HA', 'TCGA-BH-A0BT', 'TCGA-BH-A202', 'TCGA-E2-A15I']\n",
        "\n",
        "#find all gene expression subsection w/ patients w/ dicom images\n",
        "union_list = intersection([check_express, check_methyl, check_mut, check_miRNA, patient])\n",
        "u_express = rna_express[union_list]\n",
        "u_mut = mutant[union_list]\n",
        "u_methyl = methyl[union_list]\n",
        "u_miRNA = miRNA[union_list]\n",
        "\n",
        "stage_mapping = {\n",
        "    'Stage I': 0,\n",
        "    'Stage IA': 0,\n",
        "    'Stage IB': 0,\n",
        "    'Stage II': 1,\n",
        "    'Stage IIA': 1,\n",
        "    'Stage IIB': 1,\n",
        "    'Stage III': 2,\n",
        "    'Stage IIIA': 2,\n",
        "    'Stage IIIB': 2,\n",
        "    'Stage IIIC': 2\n",
        "}\n",
        "\n",
        "#concatenate into pandas dataframe\n",
        "mort_df = clinical[clinical['bcr_patient_barcode'].isin(union_list)].T\n",
        "mort_df.reset_index(drop=True, inplace=True)\n",
        "mort_df.columns = mort_df.iloc[0]\n",
        "mort_df = mort_df[1:].iloc[[3]]\n",
        "mort_df.replace(stage_mapping, inplace=True)\n",
        "#matrix of concatenated gene expression, last row is stage of cancer\n",
        "u_all_gene_exp = pd.concat([u_express, u_mut, u_methyl, u_miRNA, mort_df], ignore_index=True)\n",
        "#test_array = np.nan_to_num(u_all_gene_exp.iloc[:-1].T.to_numpy(), nan = 0)\n",
        "mort_array = u_all_gene_exp.iloc[-1].to_numpy()\n",
        "\n",
        "#train and model the RF\n",
        "#data, concatenated matrix of all genes\n",
        "gene_exp = u_all_gene_exp.iloc[:-1]\n",
        "X = np.nan_to_num(gene_exp.T.to_numpy(), nan = 0)\n",
        "y = mort_array\n",
        "\n",
        "#initialize a random forest classifier\n",
        "random_forest_class = RandomForestClassifier(min_samples_leaf=3)\n",
        "\n",
        "#start a leave one out object\n",
        "leave_one = LeaveOneOut()\n",
        "\n",
        "#make an accurate list and prediction list\n",
        "accuracy = []\n",
        "rf_predict = []\n",
        "\n",
        "#loop through the leave one out and train the random forest\n",
        "for train, test in leave_one.split(X):\n",
        "    X_train, X_test = X[train], X[test]\n",
        "    y_train, y_test = y[train], y[test]\n",
        "\n",
        "    random_forest_class.fit(X_train, y_train)\n",
        "\n",
        "    #predict\n",
        "    predicted = random_forest_class.predict(X_test)\n",
        "    rf_predict.append(predicted[0])\n",
        "\n",
        "    #accuracy\n",
        "    acc = accuracy_score(y_test, predicted)\n",
        "    accuracy.append(acc)\n",
        "mean_acc = np.mean(accuracy)\n",
        "print(\"Mean Accuracy:\", mean_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50dda9b8-72ec-43a0-851f-04cc438fa466",
      "metadata": {
        "id": "50dda9b8-72ec-43a0-851f-04cc438fa466"
      },
      "outputs": [],
      "source": [
        "# Plot the tree using the plot_tree function from sklearn\n",
        "first_tree = random_forest_class.estimators_[0]\n",
        "plt.figure(figsize=(20,10))  # Set figure size to make the tree more readable\n",
        "stages = np.array([\"stage 1\", \"stage 2\", \"stage 3\"])\n",
        "plot_tree(first_tree, feature_names=features, class_names=stages, filled=True)\n",
        "plt.title(\"Decision Tree from the Random Forest\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3bace0c-4463-4c93-99d5-cbed989faf98",
      "metadata": {
        "id": "d3bace0c-4463-4c93-99d5-cbed989faf98"
      },
      "outputs": [],
      "source": [
        "patient_list = u_all_gene_exp.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5854dc0-01e5-4408-bf58-b4770c46589d",
      "metadata": {
        "id": "f5854dc0-01e5-4408-bf58-b4770c46589d"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c754c62a-0d7f-4d29-a7f3-0afc6ef9002b",
      "metadata": {
        "id": "c754c62a-0d7f-4d29-a7f3-0afc6ef9002b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import cv2\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import pandas as pd\n",
        "\n",
        "# Define the input shape for the CNN (standard for most models working with RGB images)\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Build a custom CNN model\n",
        "model = Sequential([\n",
        "    # First convolutional layer with 32 filters and ReLU activation\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    MaxPooling2D((2, 2)),  # Max pooling to reduce spatial dimensions\n",
        "\n",
        "    # Second convolutional layer with 64 filters\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Third convolutional layer with 128 filters\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten layer to transform 3D feature maps to 1D feature vector\n",
        "    Flatten(),\n",
        "\n",
        "    # Fully connected layer with 256 neurons and dropout for regularization\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # Second fully connected layer with 128 neurons and dropout\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Output layer with softmax activation for three-class classification (stage 1, 2, 3)\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with Adam optimizer and categorical crossentropy loss\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary for a detailed view of layers and parameters\n",
        "model.summary()\n",
        "\n",
        "# Load the CSV file containing patient data\n",
        "directory = \"/Users/angelaxu/Desktop/machine_learning_2024/final_project/files/TCGA-BRCA/\"\n",
        "csv_path = directory + \"ml_project_patient_data.csv\"\n",
        "patient_data = pd.read_csv(csv_path)\n",
        "\n",
        "# Filter and map the ajcc_neoplasm_disease_stage to numeric labels\n",
        "stage_mapping = {\n",
        "    'Stage I': 0,\n",
        "    'Stage IA': 0,\n",
        "    'Stage IB': 0,\n",
        "    'Stage II': 1,\n",
        "    'Stage IIA': 1,\n",
        "    'Stage IIB': 1,\n",
        "    'Stage III': 2,\n",
        "    'Stage IIIA': 2,\n",
        "    'Stage IIIB': 2,\n",
        "    'Stage IIIC': 2\n",
        "}\n",
        "\n",
        "# Exclude Stage IV\n",
        "patient_data = patient_data[patient_data['ajcc_neoplasm_disease_stage'].isin(stage_mapping.keys())]\n",
        "patient_data['stage_label'] = patient_data['ajcc_neoplasm_disease_stage'].map(stage_mapping)\n",
        "\n",
        "# Create a mapping of patient IDs to stage labels\n",
        "stage_label_mapping = {\n",
        "    row['bcr_patient_barcode']: row['stage_label']\n",
        "    for _, row in patient_data.iterrows()\n",
        "}\n",
        "\n",
        "# Function to load and preprocess a single DICOM image\n",
        "def preprocess_dicom(filepath):\n",
        "    dicom = pydicom.dcmread(filepath)  # Read DICOM file\n",
        "    image = dicom.pixel_array  # Extract image data\n",
        "\n",
        "    # Handle different data types by scaling to 8-bit if necessary\n",
        "    if image.dtype != np.uint8:\n",
        "        image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "    # Check if the image is grayscale (single channel) or already multi-channel\n",
        "    if len(image.shape) == 2 or image.shape[-1] == 1:  # Grayscale image\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Convert to RGB\n",
        "\n",
        "    # Resize to 224x224 and normalize pixel values\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image / 255.0  # Normalize pixel values to range [0, 1]\n",
        "\n",
        "    return image\n",
        "\n",
        "# Function to load and preprocess DICOM images from a structured directory using multithreading\n",
        "def load_dicom_images(directory):\n",
        "    images = []  # List to hold image data\n",
        "    labels = []  # List to hold corresponding labels\n",
        "    file_label_pairs = []  # Collect all file paths and their labels\n",
        "    patient_ids_list = [] # save the patient ids\n",
        "\n",
        "    # Traverse the directory structure\n",
        "    for patient_folder in os.listdir(directory):\n",
        "        patient_path = os.path.join(directory, patient_folder)\n",
        "        if os.path.isdir(patient_path):\n",
        "            for date_folder in os.listdir(patient_path):\n",
        "                date_path = os.path.join(patient_path, date_folder)\n",
        "                if os.path.isdir(date_path):\n",
        "                    for location_folder in os.listdir(date_path):\n",
        "                        location_path = os.path.join(date_path, location_folder)\n",
        "                        if os.path.isdir(location_path):\n",
        "                            for file in os.listdir(location_path):\n",
        "                                filepath = os.path.join(location_path, file)\n",
        "                                if filepath.endswith('.dcm'):  # Check for DICOM file extension\n",
        "                                    # Assign label based on stage label mapping\n",
        "                                    patient_id = patient_folder.replace('.', '-')\n",
        "                                    label = stage_label_mapping.get(patient_id, None)\n",
        "                                    if label is not None:\n",
        "                                        file_label_pairs.append((filepath, label))\n",
        "                                        patient_ids_list.append(patient_id)\n",
        "\n",
        "    # Use multithreading to process images faster\n",
        "    def process_pair(pair):\n",
        "        filepath, label = pair\n",
        "        image = preprocess_dicom(filepath)\n",
        "        return image, label\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        results = executor.map(process_pair, file_label_pairs)\n",
        "\n",
        "    for image, label in results:\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels), np.array(patient_ids_list)\n",
        "\n",
        "# Load DICOM images and their labels from the specified directory\n",
        "data_directory = directory\n",
        "\n",
        "image_data, labels, patient_ids_list = load_dicom_images(data_directory)\n",
        "\n",
        "# Ensure there is data to split\n",
        "if len(image_data) == 0 or len(labels) == 0:\n",
        "    raise ValueError(\"No data loaded. Please check the DICOM files or directory structure.\")\n",
        "\n",
        "# Convert labels to categorical format (one-hot encoding for three-class classification)\n",
        "labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n",
        "\n",
        "# Split the dataset into 50% training and 50% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a714e202-2389-42aa-85d3-5f3dd30b9959",
      "metadata": {
        "id": "a714e202-2389-42aa-85d3-5f3dd30b9959"
      },
      "outputs": [],
      "source": [
        "# Train the model on the training set\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),  # Use the test set for validation during training\n",
        "    epochs=10,  # Number of training epochs\n",
        "    batch_size=32  # Number of samples per training batch\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "val_loss, val_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation Loss: {val_loss:.2f}\")\n",
        "\n",
        "# Get predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Convert predictions and true labels from one-hot encoding to class indices\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Print classification report and overall accuracy\n",
        "print(\"Classification Report:\\n\", classification_report(true_classes, predicted_classes))\n",
        "print(\"Overall Accuracy:\", accuracy_score(true_classes, predicted_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4981cf45-1d4e-4718-98f3-44914ec81689",
      "metadata": {
        "id": "4981cf45-1d4e-4718-98f3-44914ec81689"
      },
      "outputs": [],
      "source": [
        "# Get predictions on the test set\n",
        "final_predictions = model.predict(image_data)\n",
        "\n",
        "# Convert predictions and true labels from one-hot encoding to class indices\n",
        "final_predicted_classes = np.argmax(final_predictions, axis=1)\n",
        "final_true_classes = np.argmax(labels, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "708c0aef-b0e2-4943-8051-c20e4cecad38",
      "metadata": {
        "id": "708c0aef-b0e2-4943-8051-c20e4cecad38",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Print classification report and overall accuracy\n",
        "print(\"Classification Report:\\n\", classification_report(final_true_classes, final_predicted_classes))\n",
        "print(\"Overall Accuracy:\", accuracy_score(final_true_classes, final_predicted_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58b240e5-54a3-4c78-9f91-296213eba812",
      "metadata": {
        "id": "58b240e5-54a3-4c78-9f91-296213eba812",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#rearrange the prediction to match the patient - classify by most common image classifier\n",
        "patient_dic = {}\n",
        "for i in range(len(patient_ids_list)):\n",
        "    if patient_ids_list[i] not in patient_dic:\n",
        "        patient_dic[patient_ids_list[i]] = [final_predicted_classes[i]]\n",
        "    else:\n",
        "        patient_dic[patient_ids_list[i]].append(final_predicted_classes[i])\n",
        "\n",
        "counter_prediction = []\n",
        "for p in patient_list:\n",
        "    final = np.argmax(np.bincount(np.array(patient_dic[p])))\n",
        "    counter_prediction.append(final)\n",
        "\n",
        "cnn_counter = np.array(counter_prediction)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(mort_array, cnn_counter))\n",
        "print(\"Classification Report:\\n\", classification_report(mort_array, cnn_counter))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U4zoLD3n_66X",
      "metadata": {
        "id": "U4zoLD3n_66X"
      },
      "source": [
        "Visualization tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GZRZIMDo_6p9",
      "metadata": {
        "id": "GZRZIMDo_6p9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "def draw_cnn_diagram():\n",
        "    fig, ax = plt.subplots(figsize=(6, 10))\n",
        "\n",
        "    layers = [\n",
        "        (\"Input Layer\", \"input_shape\", 1, \"cyan\"),\n",
        "        (\"Conv2D (32 filters, 3x3)\", \"32xH/2xW/2\", 2, \"orange\"),\n",
        "        (\"MaxPooling2D (2x2)\", \"32xH/4xW/4\", 3, \"yellow\"),\n",
        "        (\"Conv2D (64 filters, 3x3)\", \"64xH/4xW/4\", 4, \"orange\"),\n",
        "        (\"MaxPooling2D (2x2)\", \"64xH/8xW/8\", 5, \"yellow\"),\n",
        "        (\"Conv2D (128 filters, 3x3)\", \"128xH/8xW/8\", 6, \"orange\"),\n",
        "        (\"MaxPooling2D (2x2)\", \"128xH/16xW/16\", 7, \"yellow\"),\n",
        "        (\"Flatten\", \"N/A\", 8, \"purple\"),\n",
        "        (\"Dense (256 neurons)\", \"256\", 9, \"green\"),\n",
        "        (\"Dropout (0.5)\", \"N/A\", 10, \"red\"),\n",
        "        (\"Dense (128 neurons)\", \"128\", 11, \"green\"),\n",
        "        (\"Dropout (0.3)\", \"N/A\", 12, \"red\"),\n",
        "        (\"Output Layer (Softmax, 3 classes)\", \"3\", 13, \"blue\"),\n",
        "    ]\n",
        "\n",
        "    # Draw each layer\n",
        "    for i, (name, shape, pos, color) in enumerate(layers):\n",
        "        ax.add_patch(Rectangle((0.5, pos), 2, 0.5, color=color, alpha=0.6))\n",
        "        ax.text(1.5, pos + 0.25, name, ha='center', va='bottom', fontsize=8)\n",
        "        ax.text(0.75, pos + 0.25, shape, ha='left', va='center', fontsize=8)\n",
        "\n",
        "    # Set axis limits and labels\n",
        "    ax.set_ylim(0, len(layers) + 1)\n",
        "    ax.set_xlim(0, 3)\n",
        "    ax.axis('off')\n",
        "    plt.title(\"CNN Architecture Diagram\", fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to draw the diagram\n",
        "draw_cnn_diagram()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1aed766-e5dd-4a8b-9caa-ed9e63db58d5",
      "metadata": {
        "id": "d1aed766-e5dd-4a8b-9caa-ed9e63db58d5"
      },
      "source": [
        "Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "500be579-5127-4469-bf9d-bf02b8eca14b",
      "metadata": {
        "id": "500be579-5127-4469-bf9d-bf02b8eca14b"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import joblib\n",
        "\n",
        "#predict is random forest output, CNN is image output (second term)\n",
        "X = np.vstack((rf_predict, cnn_counter)).T\n",
        "y = mort_array\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)\n",
        "\n",
        "# Create an AdaBoost classifier\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=50)\n",
        "\n",
        "# Fit the model to the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea4ddc2c-a966-4336-9cdf-f8446a812069",
      "metadata": {
        "id": "ea4ddc2c-a966-4336-9cdf-f8446a812069"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.18 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
