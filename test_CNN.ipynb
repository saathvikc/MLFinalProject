{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b9198d1c-048c-4a21-91b5-2a3cb09ab9c2",
      "metadata": {
        "id": "b9198d1c-048c-4a21-91b5-2a3cb09ab9c2"
      },
      "source": [
        "Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "82cd3f73-d061-4892-8790-e9344ebf74cb",
      "metadata": {
        "id": "82cd3f73-d061-4892-8790-e9344ebf74cb"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from sklearn import svm, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import plot_tree\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJhhBEn4BNWU",
        "outputId": "7d2d5237-d1e9-4d9d-a54f-1ce749e65950"
      },
      "id": "WJhhBEn4BNWU",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gbtyyo3BMHw",
        "outputId": "e0e2ab16-8ae0-43b6-df6a-a998f10bdddb"
      },
      "id": "6gbtyyo3BMHw",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "504d4944-fe3f-4411-a47a-d6edfc8d46f0",
      "metadata": {
        "id": "504d4944-fe3f-4411-a47a-d6edfc8d46f0",
        "outputId": "2a37b0d6-35fe-4909-c5c2-0ed54b892964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Human__TCGA_BRCA__UNC__RNAseq__HiSeq_RNA__01_28_2016__BI__Gene__Firehose_RSEM_log2.cct'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f80b3267f2f2>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#import metadata + gene expression data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrna_express\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_patient_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Human__TCGA_BRCA__UNC__RNAseq__HiSeq_RNA__01_28_2016__BI__Gene__Firehose_RSEM_log2.cct\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmutant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_patient_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Human__TCGA_BRCA__WUSM__Mutation__GAIIx__01_28_2016__BI__Gene__Firehose_MutSig2CV.cbt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmethyl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_patient_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Human__TCGA_BRCA__JHU_USC__Methylation__Meth450__01_28_2016__BI__Gene__Firehose_Methylation_Prepocessor.cct\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Human__TCGA_BRCA__UNC__RNAseq__HiSeq_RNA__01_28_2016__BI__Gene__Firehose_RSEM_log2.cct'"
          ]
        }
      ],
      "source": [
        "# metadata patient name has period instead of -\n",
        "def convert_patient_name(df):\n",
        "    new = [x.replace(\".\", \"-\") for x in df.columns]\n",
        "    df.columns = new\n",
        "    return df\n",
        "\n",
        "#import metadata + gene expression data\n",
        "rna_express = convert_patient_name(pd.read_csv(\"Human__TCGA_BRCA__UNC__RNAseq__HiSeq_RNA__01_28_2016__BI__Gene__Firehose_RSEM_log2.cct\", sep = \"\\t\"))\n",
        "mutant = convert_patient_name(pd.read_csv(\"Human__TCGA_BRCA__WUSM__Mutation__GAIIx__01_28_2016__BI__Gene__Firehose_MutSig2CV.cbt\", sep = \"\\t\"))\n",
        "methyl = convert_patient_name(pd.read_csv(\"Human__TCGA_BRCA__JHU_USC__Methylation__Meth450__01_28_2016__BI__Gene__Firehose_Methylation_Prepocessor.cct\", sep = \"\\t\"))\n",
        "miRNA = convert_patient_name(pd.read_csv(\"Human__TCGA_BRCA__BDGSC__miRNASeq__HS_miR__01_28_2016__BI__Gene__Firehose_RPKM_log2.cct\", sep=\"\\t\"))\n",
        "clinical = convert_patient_name(pd.read_excel('brca-clinicalforwiki.xls'))\n",
        "\n",
        "express_feature = rna_express['attrib_name'].to_numpy()\n",
        "mutant_feature = mutant['attrib_name'].to_numpy()\n",
        "methyl_feature = methyl['attrib_name'].to_numpy()\n",
        "miRNA_feature = miRNA['attrib_name'].to_numpy()\n",
        "features = np.concatenate([express_feature, mutant_feature, methyl_feature, miRNA_feature])\n",
        "\n",
        "check_express = rna_express.columns.to_list()[1:]\n",
        "check_mut = mutant.columns.to_list()[1:]\n",
        "check_methyl = methyl.columns.to_list()[1:]\n",
        "check_miRNA = miRNA.columns.to_list()[1:]\n",
        "\n",
        "# function for getting the intersection of all patients w/ gene expression and imaging data\n",
        "def intersection(list_of_list):\n",
        "    union = list_of_list[0]\n",
        "    for l in list_of_list:\n",
        "        union = list(set(union) & set(l))\n",
        "    return union\n",
        "\n",
        "#actually found out that metadata lied and not all gene expression patients indicated have dicom images, load manually\n",
        "patient = ['TCGA-BH-A28Q', 'TCGA-AR-A24X', 'TCGA-E2-A1IK', 'TCGA-E2-A1IE', 'TCGA-AR-A1AQ', 'TCGA-AR-A1AX', 'TCGA-BH-A0E2', 'TCGA-E2-A1LG', 'TCGA-E2-A1L9', 'TCGA-E2-A1L7', 'TCGA-E2-A1IJ', 'TCGA-BH-A0H3', 'TCGA-BH-A0B5', 'TCGA-E2-A1B1', 'TCGA-BH-A0DG', 'TCGA-E2-A1B6', 'TCGA-BH-A0DI', 'TCGA-E2-A15K', 'TCGA-BH-A201', 'TCGA-E2-A15J', 'TCGA-E2-A1IG', 'TCGA-AR-A1AN', 'TCGA-E2-A1II', 'TCGA-E2-A1IN', 'TCGA-AR-A24S', 'TCGA-BH-A0AZ', 'TCGA-BH-A0DV', 'TCGA-E2-A1B5', 'TCGA-BH-A0B6', 'TCGA-BH-A0HA', 'TCGA-BH-A0BT', 'TCGA-BH-A202', 'TCGA-E2-A15I']\n",
        "\n",
        "#find all gene expression subsection w/ patients w/ dicom images\n",
        "union_list = intersection([check_express, check_methyl, check_mut, check_miRNA, patient])\n",
        "u_express = rna_express[union_list]\n",
        "u_mut = mutant[union_list]\n",
        "u_methyl = methyl[union_list]\n",
        "u_miRNA = miRNA[union_list]\n",
        "\n",
        "stage_mapping = {\n",
        "    'Stage I': 0,\n",
        "    'Stage IA': 0,\n",
        "    'Stage IB': 0,\n",
        "    'Stage II': 1,\n",
        "    'Stage IIA': 1,\n",
        "    'Stage IIB': 1,\n",
        "    'Stage III': 2,\n",
        "    'Stage IIIA': 2,\n",
        "    'Stage IIIB': 2,\n",
        "    'Stage IIIC': 2\n",
        "}\n",
        "\n",
        "#concatenate into pandas dataframe\n",
        "mort_df = clinical[clinical['bcr_patient_barcode'].isin(union_list)].T\n",
        "mort_df.reset_index(drop=True, inplace=True)\n",
        "mort_df.columns = mort_df.iloc[0]\n",
        "mort_df = mort_df[1:].iloc[[3]]\n",
        "mort_df.replace(stage_mapping, inplace=True)\n",
        "#matrix of concatenated gene expression, last row is stage of cancer\n",
        "u_all_gene_exp = pd.concat([u_express, u_mut, u_methyl, u_miRNA, mort_df], ignore_index=True)\n",
        "#test_array = np.nan_to_num(u_all_gene_exp.iloc[:-1].T.to_numpy(), nan = 0)\n",
        "mort_array = u_all_gene_exp.iloc[-1].to_numpy()\n",
        "\n",
        "#train and model the RF\n",
        "#data, concatenated matrix of all genes\n",
        "gene_exp = u_all_gene_exp.iloc[:-1]\n",
        "X = np.nan_to_num(gene_exp.T.to_numpy(), nan = 0)\n",
        "y = mort_array\n",
        "\n",
        "#initialize a random forest classifier\n",
        "random_forest_class = RandomForestClassifier(min_samples_leaf=3)\n",
        "\n",
        "#start a leave one out object\n",
        "leave_one = LeaveOneOut()\n",
        "\n",
        "#make an accurate list and prediction list\n",
        "accuracy = []\n",
        "rf_predict = []\n",
        "\n",
        "#loop through the leave one out and train the random forest\n",
        "for train, test in leave_one.split(X):\n",
        "    X_train, X_test = X[train], X[test]\n",
        "    y_train, y_test = y[train], y[test]\n",
        "\n",
        "    random_forest_class.fit(X_train, y_train)\n",
        "\n",
        "    #predict\n",
        "    predicted = random_forest_class.predict(X_test)\n",
        "    rf_predict.append(predicted[0])\n",
        "\n",
        "    #accuracy\n",
        "    acc = accuracy_score(y_test, predicted)\n",
        "    accuracy.append(acc)\n",
        "mean_acc = np.mean(accuracy)\n",
        "print(\"Mean Accuracy:\", mean_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50dda9b8-72ec-43a0-851f-04cc438fa466",
      "metadata": {
        "id": "50dda9b8-72ec-43a0-851f-04cc438fa466"
      },
      "outputs": [],
      "source": [
        "# Plot the tree using the plot_tree function from sklearn\n",
        "first_tree = random_forest_class.estimators_[0]\n",
        "plt.figure(figsize=(20,10))  # Set figure size to make the tree more readable\n",
        "stages = np.array([\"stage 1\", \"stage 2\", \"stage 3\"])\n",
        "plot_tree(first_tree, feature_names=features, class_names=stages, filled=True)\n",
        "plt.title(\"Decision Tree from the Random Forest\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3bace0c-4463-4c93-99d5-cbed989faf98",
      "metadata": {
        "id": "d3bace0c-4463-4c93-99d5-cbed989faf98"
      },
      "outputs": [],
      "source": [
        "patient_list = u_all_gene_exp.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5854dc0-01e5-4408-bf58-b4770c46589d",
      "metadata": {
        "id": "f5854dc0-01e5-4408-bf58-b4770c46589d"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c754c62a-0d7f-4d29-a7f3-0afc6ef9002b",
      "metadata": {
        "id": "c754c62a-0d7f-4d29-a7f3-0afc6ef9002b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import cv2\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import pandas as pd\n",
        "\n",
        "# Define the input shape for the CNN (standard for most models working with RGB images)\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Build a custom CNN model\n",
        "model = Sequential([\n",
        "    # First convolutional layer with 32 filters and ReLU activation\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    MaxPooling2D((2, 2)),  # Max pooling to reduce spatial dimensions\n",
        "\n",
        "    # Second convolutional layer with 64 filters\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Third convolutional layer with 128 filters\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten layer to transform 3D feature maps to 1D feature vector\n",
        "    Flatten(),\n",
        "\n",
        "    # Fully connected layer with 256 neurons and dropout for regularization\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # Second fully connected layer with 128 neurons and dropout\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Output layer with softmax activation for three-class classification (stage 1, 2, 3)\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with Adam optimizer and categorical crossentropy loss\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary for a detailed view of layers and parameters\n",
        "model.summary()\n",
        "\n",
        "# Load the CSV file containing patient data\n",
        "directory = \"/Users/angelaxu/Desktop/machine_learning_2024/final_project/files/TCGA-BRCA/\"\n",
        "csv_path = directory + \"ml_project_patient_data.csv\"\n",
        "patient_data = pd.read_csv(csv_path)\n",
        "\n",
        "# Filter and map the ajcc_neoplasm_disease_stage to numeric labels\n",
        "stage_mapping = {\n",
        "    'Stage I': 0,\n",
        "    'Stage IA': 0,\n",
        "    'Stage IB': 0,\n",
        "    'Stage II': 1,\n",
        "    'Stage IIA': 1,\n",
        "    'Stage IIB': 1,\n",
        "    'Stage III': 2,\n",
        "    'Stage IIIA': 2,\n",
        "    'Stage IIIB': 2,\n",
        "    'Stage IIIC': 2\n",
        "}\n",
        "\n",
        "# Exclude Stage IV\n",
        "patient_data = patient_data[patient_data['ajcc_neoplasm_disease_stage'].isin(stage_mapping.keys())]\n",
        "patient_data['stage_label'] = patient_data['ajcc_neoplasm_disease_stage'].map(stage_mapping)\n",
        "\n",
        "# Create a mapping of patient IDs to stage labels\n",
        "stage_label_mapping = {\n",
        "    row['bcr_patient_barcode']: row['stage_label']\n",
        "    for _, row in patient_data.iterrows()\n",
        "}\n",
        "\n",
        "# Function to load and preprocess a single DICOM image\n",
        "def preprocess_dicom(filepath):\n",
        "    dicom = pydicom.dcmread(filepath)  # Read DICOM file\n",
        "    image = dicom.pixel_array  # Extract image data\n",
        "\n",
        "    # Handle different data types by scaling to 8-bit if necessary\n",
        "    if image.dtype != np.uint8:\n",
        "        image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "    # Check if the image is grayscale (single channel) or already multi-channel\n",
        "    if len(image.shape) == 2 or image.shape[-1] == 1:  # Grayscale image\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Convert to RGB\n",
        "\n",
        "    # Resize to 224x224 and normalize pixel values\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image / 255.0  # Normalize pixel values to range [0, 1]\n",
        "\n",
        "    return image\n",
        "\n",
        "# Function to load and preprocess DICOM images from a structured directory using multithreading\n",
        "def load_dicom_images(directory):\n",
        "    images = []  # List to hold image data\n",
        "    labels = []  # List to hold corresponding labels\n",
        "    file_label_pairs = []  # Collect all file paths and their labels\n",
        "    patient_ids_list = [] # save the patient ids\n",
        "\n",
        "    # Traverse the directory structure\n",
        "    for patient_folder in os.listdir(directory):\n",
        "        patient_path = os.path.join(directory, patient_folder)\n",
        "        if os.path.isdir(patient_path):\n",
        "            for date_folder in os.listdir(patient_path):\n",
        "                date_path = os.path.join(patient_path, date_folder)\n",
        "                if os.path.isdir(date_path):\n",
        "                    for location_folder in os.listdir(date_path):\n",
        "                        location_path = os.path.join(date_path, location_folder)\n",
        "                        if os.path.isdir(location_path):\n",
        "                            for file in os.listdir(location_path):\n",
        "                                filepath = os.path.join(location_path, file)\n",
        "                                if filepath.endswith('.dcm'):  # Check for DICOM file extension\n",
        "                                    # Assign label based on stage label mapping\n",
        "                                    patient_id = patient_folder.replace('.', '-')\n",
        "                                    label = stage_label_mapping.get(patient_id, None)\n",
        "                                    if label is not None:\n",
        "                                        file_label_pairs.append((filepath, label))\n",
        "                                        patient_ids_list.append(patient_id)\n",
        "\n",
        "    # Use multithreading to process images faster\n",
        "    def process_pair(pair):\n",
        "        filepath, label = pair\n",
        "        image = preprocess_dicom(filepath)\n",
        "        return image, label\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        results = executor.map(process_pair, file_label_pairs)\n",
        "\n",
        "    for image, label in results:\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels), np.array(patient_ids_list)\n",
        "\n",
        "# Load DICOM images and their labels from the specified directory\n",
        "data_directory = directory\n",
        "\n",
        "image_data, labels, patient_ids_list = load_dicom_images(data_directory)\n",
        "\n",
        "# Ensure there is data to split\n",
        "if len(image_data) == 0 or len(labels) == 0:\n",
        "    raise ValueError(\"No data loaded. Please check the DICOM files or directory structure.\")\n",
        "\n",
        "# Convert labels to categorical format (one-hot encoding for three-class classification)\n",
        "labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n",
        "\n",
        "# Split the dataset into 50% training and 50% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a714e202-2389-42aa-85d3-5f3dd30b9959",
      "metadata": {
        "id": "a714e202-2389-42aa-85d3-5f3dd30b9959"
      },
      "outputs": [],
      "source": [
        "# Train the model on the training set\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),  # Use the test set for validation during training\n",
        "    epochs=10,  # Number of training epochs\n",
        "    batch_size=32  # Number of samples per training batch\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "val_loss, val_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation Loss: {val_loss:.2f}\")\n",
        "\n",
        "# Get predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Convert predictions and true labels from one-hot encoding to class indices\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Print classification report and overall accuracy\n",
        "print(\"Classification Report:\\n\", classification_report(true_classes, predicted_classes))\n",
        "print(\"Overall Accuracy:\", accuracy_score(true_classes, predicted_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4981cf45-1d4e-4718-98f3-44914ec81689",
      "metadata": {
        "id": "4981cf45-1d4e-4718-98f3-44914ec81689"
      },
      "outputs": [],
      "source": [
        "# Get predictions on the test set\n",
        "final_predictions = model.predict(image_data)\n",
        "\n",
        "# Convert predictions and true labels from one-hot encoding to class indices\n",
        "final_predicted_classes = np.argmax(final_predictions, axis=1)\n",
        "final_true_classes = np.argmax(labels, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "708c0aef-b0e2-4943-8051-c20e4cecad38",
      "metadata": {
        "scrolled": true,
        "id": "708c0aef-b0e2-4943-8051-c20e4cecad38"
      },
      "outputs": [],
      "source": [
        "# Print classification report and overall accuracy\n",
        "print(\"Classification Report:\\n\", classification_report(final_true_classes, final_predicted_classes))\n",
        "print(\"Overall Accuracy:\", accuracy_score(final_true_classes, final_predicted_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58b240e5-54a3-4c78-9f91-296213eba812",
      "metadata": {
        "scrolled": true,
        "id": "58b240e5-54a3-4c78-9f91-296213eba812"
      },
      "outputs": [],
      "source": [
        "#rearrange the prediction to match the patient - classify by most common image classifier\n",
        "patient_dic = {}\n",
        "for i in range(len(patient_ids_list)):\n",
        "    if patient_ids_list[i] not in patient_dic:\n",
        "        patient_dic[patient_ids_list[i]] = [final_predicted_classes[i]]\n",
        "    else:\n",
        "        patient_dic[patient_ids_list[i]].append(final_predicted_classes[i])\n",
        "\n",
        "counter_prediction = []\n",
        "for p in patient_list:\n",
        "    final = np.argmax(np.bincount(np.array(patient_dic[p])))\n",
        "    counter_prediction.append(final)\n",
        "\n",
        "cnn_counter = np.array(counter_prediction)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(mort_array, cnn_counter))\n",
        "print(\"Classification Report:\\n\", classification_report(mort_array, cnn_counter))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization tools"
      ],
      "metadata": {
        "id": "U4zoLD3n_66X"
      },
      "id": "U4zoLD3n_66X"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "def draw_cnn_diagram():\n",
        "    fig, ax = plt.subplots(figsize=(6, 10))\n",
        "\n",
        "    layers = [\n",
        "        (\"Input Layer\", \"input_shape\", 1, \"cyan\"),\n",
        "        (\"Conv2D (32 filters, 3x3)\", \"32xH/2xW/2\", 2, \"orange\"),\n",
        "        (\"MaxPooling2D (2x2)\", \"32xH/4xW/4\", 3, \"yellow\"),\n",
        "        (\"Conv2D (64 filters, 3x3)\", \"64xH/4xW/4\", 4, \"orange\"),\n",
        "        (\"MaxPooling2D (2x2)\", \"64xH/8xW/8\", 5, \"yellow\"),\n",
        "        (\"Conv2D (128 filters, 3x3)\", \"128xH/8xW/8\", 6, \"orange\"),\n",
        "        (\"MaxPooling2D (2x2)\", \"128xH/16xW/16\", 7, \"yellow\"),\n",
        "        (\"Flatten\", \"N/A\", 8, \"purple\"),\n",
        "        (\"Dense (256 neurons)\", \"256\", 9, \"green\"),\n",
        "        (\"Dropout (0.5)\", \"N/A\", 10, \"red\"),\n",
        "        (\"Dense (128 neurons)\", \"128\", 11, \"green\"),\n",
        "        (\"Dropout (0.3)\", \"N/A\", 12, \"red\"),\n",
        "        (\"Output Layer (Softmax, 3 classes)\", \"3\", 13, \"blue\"),\n",
        "    ]\n",
        "\n",
        "    # Draw each layer\n",
        "    for i, (name, shape, pos, color) in enumerate(layers):\n",
        "        ax.add_patch(Rectangle((0.5, pos), 2, 0.5, color=color, alpha=0.6))\n",
        "        ax.text(1.5, pos + 0.25, name, ha='center', va='bottom', fontsize=8)\n",
        "        ax.text(0.75, pos + 0.25, shape, ha='left', va='center', fontsize=8)\n",
        "\n",
        "    # Set axis limits and labels\n",
        "    ax.set_ylim(0, len(layers) + 1)\n",
        "    ax.set_xlim(0, 3)\n",
        "    ax.axis('off')\n",
        "    plt.title(\"CNN Architecture Diagram\", fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to draw the diagram\n",
        "draw_cnn_diagram()\n"
      ],
      "metadata": {
        "id": "GZRZIMDo_6p9"
      },
      "id": "GZRZIMDo_6p9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d1aed766-e5dd-4a8b-9caa-ed9e63db58d5",
      "metadata": {
        "id": "d1aed766-e5dd-4a8b-9caa-ed9e63db58d5"
      },
      "source": [
        "Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "500be579-5127-4469-bf9d-bf02b8eca14b",
      "metadata": {
        "id": "500be579-5127-4469-bf9d-bf02b8eca14b"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import joblib\n",
        "\n",
        "#predict is random forest output, CNN is image output (second term)\n",
        "X = np.vstack((rf_predict, cnn_counter)).T\n",
        "y = mort_array\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)\n",
        "\n",
        "# Create an AdaBoost classifier\n",
        "clf = AdaBoostClassifier(n_estimators=50, random_state=50)\n",
        "\n",
        "# Fit the model to the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea4ddc2c-a966-4336-9cdf-f8446a812069",
      "metadata": {
        "id": "ea4ddc2c-a966-4336-9cdf-f8446a812069"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}